{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "  _target_: starfish.model.FasterRCNNLightning\n",
      "  num_classes: 2\n",
      "  learning_rate: 0.001\n",
      "  momentum: 0.9\n",
      "  weight_decay: 0.0005\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    lr: 0.001\n",
      "    weight_decay: 0.01\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.StepLR\n",
      "    _partial_: true\n",
      "    step_size: 3\n",
      "    gamma: 0.1\n",
      "  compile: false\n",
      "data:\n",
      "  _target_: starfish.data.StarfishDataModule\n",
      "  data_path: data/raw\n",
      "  batch_size: 4\n",
      "  train_val_test_split:\n",
      "  - 0.8\n",
      "  - 0.1\n",
      "  - 0.1\n",
      "  subset: 0.002\n",
      "  num_workers: 8\n",
      "trainer:\n",
      "  _target_: pytorch_lightning.Trainer\n",
      "  min_epochs: 1\n",
      "  max_epochs: 2\n",
      "  accelerator: cpu\n",
      "  devices: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from starfish.data import StarfishDataModule\n",
    "from starfish.model import FasterRCNNLightning\n",
    "\n",
    "from pprint import pprint\n",
    "# Set the environment variable HYDRA_FULL_ERROR=1 to see the full stack trace\n",
    "os.environ['HYDRA_FULL_ERROR'] = '1'\n",
    "\n",
    "os.environ['PROJECT_ROOT'] = '/Users/moustholmes/starfishDetection'\n",
    "\n",
    "# Change the current working directory to the project root\n",
    "os.chdir('/Users/moustholmes/starfishDetection')\n",
    "\n",
    "initialize(version_base=None, config_path='configs', job_name='notebook')\n",
    "\n",
    "cfg_train = compose(config_name='main_config',) #overrides=['experiment=effect_gaussian_nll'])\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<starfish.data.StarfishDataModule object at 0x13f8664d0>\n",
      "Loading 10 images.\n"
     ]
    }
   ],
   "source": [
    "data = instantiate(cfg_train.data)\n",
    "print(data)\n",
    "data.setup()\n",
    "train_dataloader = data.train_dataloader()\n",
    "batch = next(iter(train_dataloader))\n",
    "x, y = batch\n",
    "assert len(x) == data.batch_size\n",
    "assert len(y) == data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterRCNNLightning(\n",
      "  (model): FasterRCNN(\n",
      "    (transform): GeneralizedRCNNTransform(\n",
      "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "        Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
      "    )\n",
      "    (backbone): BackboneWithFPN(\n",
      "      (body): IntermediateLayerGetter(\n",
      "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (fpn): FeaturePyramidNetwork(\n",
      "        (inner_blocks): ModuleList(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (layer_blocks): ModuleList(\n",
      "          (0-3): 4 x Conv2dNormActivation(\n",
      "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (extra_blocks): LastLevelMaxPool()\n",
      "      )\n",
      "    )\n",
      "    (rpn): RegionProposalNetwork(\n",
      "      (anchor_generator): AnchorGenerator()\n",
      "      (head): RPNHead(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (roi_heads): RoIHeads(\n",
      "      (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
      "      (box_head): TwoMLPHead(\n",
      "        (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "        (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      )\n",
      "      (box_predictor): FastRCNNPredictor(\n",
      "        (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "        (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg_train.model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/moustholmes/miniconda3/envs/starfish/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/Users/moustholmes/miniconda3/envs/starfish/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = instantiate(cfg_train.trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | FasterRCNN | 41.3 M\n",
      "-------------------------------------\n",
      "41.1 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "41.3 M    Total params\n",
      "165.197   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moustholmes/miniconda3/envs/starfish/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:20<00:20, 20.70s/it, v_num=4, train_loss_classifier=0.451, train_loss_box_reg=0.00817, train_loss_objectness=0.337, train_loss_rpn_box_reg=0.0167, train_total_loss=0.813, train_AP=0.0278]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moustholmes/miniconda3/envs/starfish/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('train_AP', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2/2 [00:56<00:00, 28.04s/it, v_num=4, train_loss_classifier=0.130, train_loss_box_reg=0.00915, train_loss_objectness=3.190, train_loss_rpn_box_reg=0.0387, train_total_loss=3.370, train_AP=0.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2/2 [00:56<00:00, 28.16s/it, v_num=4, train_loss_classifier=0.130, train_loss_box_reg=0.00915, train_loss_objectness=3.190, train_loss_rpn_box_reg=0.0387, train_total_loss=3.370, train_AP=0.000]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
